{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 -- MapReduce\n",
    "\n",
    "What you will do in this assignment is help construct a small MapReduce program. MapReduce is framework which Google uses to process petabytes of data every day using parallel computing methods. In this assignment, we'll be recreating it on a small scale.\n",
    "\n",
    "The way that MapReduce works is that it splits data into a bunch of little tasks. There are three separate tasks: the Map task, the Intermediate task, and the Reduce task.\n",
    "\n",
    "1. Map task – take some of data and split them between distinct keys and values\n",
    "2. Intermediate task – shuffle the keys into some logically order (this usually means sorting them)\n",
    "3. Reduce task – group data by keys and apply some function to their values\n",
    "\n",
    "The figure below shows the typical MapReduce processing flow. \n",
    "\n",
    "![](img/MapReduceWordCount-sourced.png)\n",
    "\n",
    "## Task -- WordCount\n",
    "\n",
    "What this assignment will do is create a program which will create a wordcounting program. You will be required to complete several <code>TODOs</code> to make the code operate correctly. If you can run this entire notebook and get it to produce the right result without error, you have completely the assignment.\n",
    "\n",
    "To get started, you can download this notebook by clicking Download on the repository page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def map(doc):\n",
    "    \"\"\"\n",
    "        The map function. This function opens a single file, cleans the file of punctuation,\n",
    "        converts all of the text to lowercase, then emits the word plus a value for each word \n",
    "        in the document. In this case the value is constant (i.e. it is 1).\n",
    "    \"\"\"\n",
    "    import string\n",
    "    out = []\n",
    "    lines = open(doc, \"r\", encoding = \"utf-8\").read().split(\"\\n\")\n",
    "    for line in lines:\n",
    "        ## removes the whitespace\n",
    "        line = line.strip()\n",
    "\n",
    "        ## removes punctuation\n",
    "        line = line.translate( str.maketrans(string.punctuation, ' ' * len(string.punctuation)) )\n",
    "\n",
    "        ## converts the text to lowercase \n",
    "        line = line.lower()\n",
    "\n",
    "        ## this splits words at all whitespace\n",
    "        words = line.split(None)\n",
    "\n",
    "        ## prints out all the words with a count of 1\n",
    "        for w in words:\n",
    "            emit = (w, 1)\n",
    "            out.append(emit)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reduce(words):\n",
    "    \"\"\"\n",
    "        The reduce function. This loops through all the words in all the documents and sums\n",
    "        counts of all the words.\n",
    "    \"\"\"\n",
    "    c_key   = None\n",
    "    c_count = 0\n",
    "    counted = []\n",
    "\n",
    "    # input comes from the list of all words\n",
    "    for key, count in words:\n",
    "        if c_key == key:\n",
    "            c_count += count\n",
    "        else:\n",
    "            if c_key:\n",
    "                # append result to counted\n",
    "                counted.append( (c_key, c_count) )\n",
    "            c_count = count\n",
    "            c_key   = key\n",
    "\n",
    "    ## append the last word if it exists\n",
    "    if c_key == key:\n",
    "        counted.append( (c_key, c_count) )\n",
    "\n",
    "    return counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 38333),\n",
       " ('of', 18678),\n",
       " ('to', 16901),\n",
       " ('and', 14130),\n",
       " ('in', 12190),\n",
       " ('is', 8683),\n",
       " ('a', 8564),\n",
       " ('that', 8381),\n",
       " ('this', 6366),\n",
       " ('we', 6067)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This brings all the different steps togethere here.\n",
    "\"\"\"\n",
    "\n",
    "import glob\n",
    "\n",
    "## map task\n",
    "docs = list(glob.iglob(\"/Users/ahanna/assignment_1-master/data/*.en\"))\n",
    "words = []\n",
    "for doc in docs:\n",
    "    words.extend(map(doc))\n",
    "\n",
    "## intermediate sorting task\n",
    "words = sorted(words)\n",
    "\n",
    "## reduce task\n",
    "wordcount = reduce(words)\n",
    "\n",
    "## as a final check, sorting in descending order the most used words\n",
    "wordcount = sorted(wordcount, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "## TODO 10: Take a slice of the first 10 elements of this list.\n",
    "## This is a final check to display the 10 most frequently used words.\n",
    "wordcount[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
